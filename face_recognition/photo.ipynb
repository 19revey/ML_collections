{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image,ImageDraw,ImageOps\n",
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "# from sklearn import neighbors\n",
    "# from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "# image = face_recognition.load_image_file(\"photos/DSC05406.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare jpg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./photos/DSC05301.JPG\n",
      "./photos/DSC05300.JPG\n",
      "./photos/DSC05299.JPG\n",
      "./photos/DSC05298.JPG\n",
      "./photos/DSC05297.JPG\n",
      "./photos/DSC05296.JPG\n",
      "./photos/DSC05295.JPG\n",
      "./photos/DSC05294.JPG\n",
      "./photos/DSC05293.JPG\n",
      "./photos/DSC05292.JPG\n",
      "./photos/DSC05291.JPG\n",
      "./photos/DSC05290.JPG\n",
      "./photos/DSC05289.JPG\n",
      "./photos/DSC05288.JPG\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "photo_path = glob.glob(\"./photos/*.JPG\")\n",
    "\n",
    "def rotate_if_landscape(photo_path):\n",
    "    # Open the image\n",
    "    \n",
    "    try:\n",
    "        im=Image.open(photo_path)\n",
    "        im=ImageOps.exif_transpose(im)\n",
    "    except:\n",
    "        im=Image.open(photo_path)\n",
    "\n",
    "    im.save(photo_path)\n",
    "\n",
    "# Example usage:\n",
    "        \n",
    "for img in photo_path:\n",
    "    # rotate_if_landscape(img)\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read and store pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.read_pic at 0x7f7ac499feb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class read_pic_config:\n",
    "    pic_path: str = None  # Default value set to None\n",
    "    artifact_path: str= \"./artifacts/lib_pic.pkl\"\n",
    "    def __post_init__(self):\n",
    "        if self.pic_path is None:\n",
    "            self.pic_path = glob.glob(\"./photos/*.JPG\")\n",
    "\n",
    "class read_pic:\n",
    "    def __init__(self) -> None:\n",
    "        self.config=read_pic_config()\n",
    "        self.photo_path=self.config.pic_path\n",
    "        self.artifact_path=self.config.artifact_path\n",
    "        self.save_image()\n",
    "    \n",
    "    def save_image(self):\n",
    "        pic_id=0\n",
    "        self.pic_dict={}\n",
    "        for path in self.photo_path:\n",
    "            self.pic_dict[pic_id]=path\n",
    "            pic_id=pic_id+1\n",
    "            # im=Image.open(photo_path)\n",
    "            # try:\n",
    "            #     pic_dict[pic_id]=ImageOps.exif_transpose(im)\n",
    "            # except:\n",
    "            #     pic_dict[pic_id]=im\n",
    "        \n",
    "        os.makedirs(os.path.dirname(self.artifact_path),exist_ok=True)\n",
    "        with open(self.artifact_path, 'wb') as f:\n",
    "            pickle.dump(self.pic_dict, f)\n",
    "\n",
    "\n",
    "read_pic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_pic_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mread_pic_config\u001b[49m\u001b[38;5;241m.\u001b[39martifact_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     pics \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m pics\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_pic_config' is not defined"
     ]
    }
   ],
   "source": [
    "with open(read_pic_config.artifact_path, 'rb') as f:\n",
    "    pics = pickle.load(f)\n",
    "\n",
    "pics\n",
    "# x=Image.open(pics[1])\n",
    "# x.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.batch_embedding at 0x7f7ac4935750>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "@dataclass\n",
    "class batch_embedding_config:\n",
    "    encoding_path: str = './artifacts/lib_encode.pkl'  # Default value set to None\n",
    "    face_path: str = './artifacts/lib_face.pkl' \n",
    "class batch_embedding:\n",
    "    def __init__(self):\n",
    "        self.faces=[]\n",
    "        pic_path=read_pic_config().artifact_path\n",
    "        self.encoding_path=batch_embedding_config().encoding_path\n",
    "        self.face_path=batch_embedding_config().face_path\n",
    "        with open(pic_path, 'rb') as f:\n",
    "            self.pics_dict = pickle.load(f)\n",
    "        \n",
    "        self.encodings=np.empty((0, 129))\n",
    "        self.encode()\n",
    "        \n",
    "\n",
    "    def encode(self):\n",
    "        for pic_id,pic in self.pics_dict.items():\n",
    "            X_img = face_recognition.load_image_file(pic)\n",
    "            X_face_locations = face_recognition.face_locations(X_img)\n",
    "            if len(X_face_locations)==0:\n",
    "                continue\n",
    "\n",
    "            faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "            num_rows = len(faces_encodings)\n",
    "            index_array=np.full((num_rows,1),pic_id)  \n",
    "            faces_encodings_with_index = np.hstack((index_array, faces_encodings))\n",
    "\n",
    "            for face_location in X_face_locations:\n",
    "                # Print the location of each face in this image\n",
    "                top, right, bottom, left = face_location\n",
    "                face_image = X_img[top:bottom, left:right]\n",
    "                pil_image = Image.fromarray(face_image)\n",
    "                self.faces.append(pil_image)\n",
    "\n",
    "            self.encodings=np.vstack((self.encodings, faces_encodings_with_index))\n",
    "\n",
    "        with open(self.encoding_path, 'wb') as f:\n",
    "            pickle.dump(self.encodings, f)\n",
    "        with open(self.face_path, 'wb') as f:\n",
    "            pickle.dump(self.faces, f)\n",
    "        \n",
    "\n",
    "batch_embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(batch_embedding_config.encoding_path, 'rb') as f:\n",
    "    ecode = pickle.load(f)\n",
    "with open(batch_embedding_config.face_path, 'rb') as f:\n",
    "    face = pickle.load(f)\n",
    "\n",
    "len(ecode)\n",
    "\n",
    "# k=6\n",
    "# for i  in face[k]:\n",
    "#     i.show()\n",
    "# img=Image.open(pics_dict[k])\n",
    "# img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class group_pic_config:\n",
    "    group_path: str = './artifacts/group_id.pkl'  \n",
    "    group_face_path: str = './artifacts/group_face.pkl'  \n",
    "    group_encode: str = './artifacts/group_encode.pkl'  \n",
    "\n",
    "class group_pic:\n",
    "    def __init__(self) -> None:\n",
    "        config=group_pic_config\n",
    "        self.group_path=config.group_path\n",
    "        self.group_face_path=config.group_face_path\n",
    "        self.group_encode= config.group_encode\n",
    "\n",
    "        encoding_path=batch_embedding_config.encoding_path\n",
    "        face_lib_path=batch_embedding_config.face_path\n",
    "\n",
    "        \n",
    "        with open(encoding_path, 'rb') as f:\n",
    "            self.encoding = pickle.load(f)\n",
    "        with open(face_lib_path, 'rb') as f:\n",
    "            self.face = pickle.load(f)\n",
    "\n",
    "        self.store={}\n",
    "        self.store_id={}\n",
    "        self.faces={}\n",
    "\n",
    "        self.group()\n",
    " \n",
    "    def group(self):\n",
    "        for i,k in enumerate(self.encoding):\n",
    "            action=False\n",
    "            curr_image_cluster_id=None   \n",
    "\n",
    "            img_id:int=k[0]\n",
    "            img= k[1:]\n",
    "                   \n",
    "            for cluster_id,cluster_embeddings in self.store.items():\n",
    "                results=face_recognition.compare_faces(cluster_embeddings,img,tolerance=0.4)\n",
    "                # results=face_recognition.compare_faces([np.mean(cluster_embeddings,axis=0)],img,tolerance=0.3)\n",
    "                # print(\"results %s %s\" % (results, cluster_id))\n",
    "\n",
    "                if all(results):\n",
    "                    curr_image_cluster_id = cluster_id\n",
    "                    self.store.get(cluster_id).append(img)\n",
    "                    self.store_id.get(cluster_id).append(img_id)\n",
    "                    self.faces.get(cluster_id).append(self.face[i])\n",
    "                    action=True\n",
    "\n",
    "            if not action:\n",
    "                curr_image_cluster_id=\"person_%s\" % (len(self.store.keys()) + 1)\n",
    "                self.store[curr_image_cluster_id]=[img]\n",
    "                self.store_id[curr_image_cluster_id]=[img_id]\n",
    "                self.faces[curr_image_cluster_id]=[self.face[i]]\n",
    "        \n",
    "        with open(self.group_path, 'wb') as f:\n",
    "            pickle.dump(self.store_id, f)    \n",
    "        with open(self.group_face_path, 'wb') as f:\n",
    "            pickle.dump(self.faces, f) \n",
    "        with open(self.group_encode, 'wb') as f:\n",
    "            gp_encode={}\n",
    "            for cluster_id,cluster_embeddings in self.store.items():\n",
    "                gp_encode[cluster_id]=np.mean(cluster_embeddings,axis=0)\n",
    "            \n",
    "            \n",
    "            pickle.dump(gp_encode, f) \n",
    "\n",
    "a=group_pic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.26571771 0.48717233 0.30418473 0.45711627 0.50131803\n",
      "  0.47214846 0.46467763 0.66508356 0.29435884]\n",
      " [0.26571771 0.         0.54302577 0.11214331 0.51283403 0.57362856\n",
      "  0.50680518 0.53333651 0.68298367 0.34058242]\n",
      " [0.48717233 0.54302577 0.         0.55344314 0.17809393 0.46177329\n",
      "  0.20094128 0.27566293 0.48449196 0.59698495]\n",
      " [0.30418473 0.11214331 0.55344314 0.         0.52202922 0.57018973\n",
      "  0.52589282 0.53364562 0.68180394 0.34847656]\n",
      " [0.45711627 0.51283403 0.17809393 0.52202922 0.         0.43979388\n",
      "  0.23567    0.26081552 0.47952004 0.55413044]\n",
      " [0.50131803 0.57362856 0.46177329 0.57018973 0.43979388 0.\n",
      "  0.49966742 0.42198052 0.59404954 0.57697821]\n",
      " [0.47214846 0.50680518 0.20094128 0.52589282 0.23567    0.49966742\n",
      "  0.         0.32628855 0.49579355 0.56194766]\n",
      " [0.46467763 0.53333651 0.27566293 0.53364562 0.26081552 0.42198052\n",
      "  0.32628855 0.         0.44415816 0.5761615 ]\n",
      " [0.66508356 0.68298367 0.48449196 0.68180394 0.47952004 0.59404954\n",
      "  0.49579355 0.44415816 0.         0.71256892]\n",
      " [0.29435884 0.34058242 0.59698495 0.34847656 0.55413044 0.57697821\n",
      "  0.56194766 0.5761615  0.71256892 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pic_path=read_pic_config().artifact_path\n",
    "with open(pic_path, 'rb') as f:\n",
    "    pics_dict = pickle.load(f)\n",
    "\n",
    "with open(group_pic_config.group_path, 'rb') as f:\n",
    "    group = pickle.load(f)\n",
    "\n",
    "with open(group_pic_config.group_face_path, 'rb') as f:\n",
    "    groupface = pickle.load(f)\n",
    "\n",
    "with open(group_pic_config.group_encode, 'rb') as f:\n",
    "    groupencode = pickle.load(f)\n",
    "\n",
    "# for i,j in groupface.items():\n",
    "#     # img=Image.open(pics_dict[int(i)])\n",
    "#     j[0].show()\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np\n",
    "# (groupencode.values())\n",
    "vectors = list(groupencode.values())\n",
    "data = np.array(vectors)\n",
    "similarity_matrix = pairwise_distances(data)\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save grouped pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.save_pic at 0x7f7a6b25c430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class save_pic_config:\n",
    "    pic_path: str = './results'  # Default value set to None\n",
    "class save_pic:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        with open(group_pic_config.group_face_path, 'rb') as f:\n",
    "            self.groupface = pickle.load(f)\n",
    "        self.curr_cluster = os.path.join(save_pic_config.pic_path)\n",
    "\n",
    "        with open(group_pic_config.group_path, 'rb') as f:\n",
    "            self.group = pickle.load(f)\n",
    "\n",
    "        with open(read_pic_config.artifact_path, 'rb') as f:\n",
    "            self.pics_dict = pickle.load(f)\n",
    "\n",
    "        self.save_grouped_face()\n",
    "\n",
    "    def save_grouped_pic(self):\n",
    "        \n",
    "        for key, pic in self.group.items():\n",
    "            curr_cluster = os.path.join(self.curr_cluster, key)\n",
    "            curr_cluster_dir = Path(curr_cluster)\n",
    "            curr_cluster_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "\n",
    "            img=Image.open(self.pics_dict[int()])\n",
    "\n",
    "            i=1\n",
    "            for im in pic:\n",
    "                img=Image.open(self.pics_dict[int(im)])\n",
    "\n",
    "                photo_path=os.path.join(curr_cluster,str(i)+'.jpg')\n",
    "                img.save(photo_path)\n",
    "                # print(photo_path)\n",
    "                i=i+1\n",
    "\n",
    "    def save_grouped_face(self):\n",
    "        \n",
    "        for key, pic in self.groupface.items():\n",
    "            curr_cluster = os.path.join(self.curr_cluster, key)\n",
    "            curr_cluster_dir = Path(curr_cluster)\n",
    "            curr_cluster_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            i=1\n",
    "            for im in pic:\n",
    "                # im.show()\n",
    "                # im.save(photo_path)\n",
    "                photo_path=os.path.join(curr_cluster,str(i)+'.jpg')\n",
    "                im.save(photo_path)\n",
    "                # print(photo_path)\n",
    "                i=i+1\n",
    "            \n",
    "\n",
    "save_pic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode some photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class batch_embedding:\n",
    "    def __init__(self, photo_path):\n",
    "        self.photo_paths=photo_path\n",
    "        self.photos=[]\n",
    "        self.encodings=np.empty((0, 128))\n",
    "        self.store={}\n",
    "        self.store_img={}\n",
    "\n",
    "    def encode(self):\n",
    "        for photo_path in self.photo_paths:\n",
    "            X_img = face_recognition.load_image_file(photo_path)\n",
    "            X_face_locations = face_recognition.face_locations(X_img)\n",
    "            if len(X_face_locations)==0:\n",
    "                continue\n",
    "            faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "            # print('faces encodings size is {}'.format(len(faces_encodings)))\n",
    "            # print('total encodings size is {}'.format(len(self.encodings)))\n",
    "            self.encodings=np.vstack((self.encodings, faces_encodings))\n",
    "\n",
    "            for face_location in X_face_locations:\n",
    "\n",
    "                # Print the location of each face in this image\n",
    "                top, right, bottom, left = face_location\n",
    "\n",
    "                face_image = X_img[top:bottom, left:right]\n",
    "                pil_image = Image.fromarray(face_image)\n",
    "                \n",
    "                self.photos.append(pil_image)\n",
    "                # pil_image.show()\n",
    "        with open('encodings.pkl', 'wb') as f:\n",
    "            pickle.dump(zip(self.encodings,self.photos), f)\n",
    "        return self.encodings, self.photos\n",
    "    \n",
    "    # def save(self,encodings):\n",
    "    #     with open('encodings.pkl', 'wb') as f:\n",
    "    #         pickle.dump(encodings, f)\n",
    "\n",
    "    def group(self):\n",
    "        for fe,img in zip(self.encodings,self.photos):\n",
    "            action=False\n",
    "            curr_image_cluster_id=None    \n",
    "                   \n",
    "            for cluster_id,cluster_embeddings in self.store.items():\n",
    "                results=face_recognition.compare_faces([np.mean(cluster_embeddings,axis=0)],fe,tolerance=0.4)\n",
    "                print(\"results %s %s\" % (results, cluster_id))\n",
    "\n",
    "                if all(results):\n",
    "                    curr_image_cluster_id = cluster_id\n",
    "                    self.store.get(cluster_id).append(fe)\n",
    "                    self.store_img.get(cluster_id).append(img)\n",
    "                    action=True\n",
    "\n",
    "            if not action:\n",
    "                curr_image_cluster_id=\"cluster_%s\" % (len(self.store.keys()) + 1)\n",
    "                self.store[curr_image_cluster_id]=[fe]\n",
    "                self.store_img[curr_image_cluster_id]=[img]\n",
    "        return self.store, self.store_img\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode=batch_embedding(photo_path)\n",
    "encoding,photos=encode.encode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = encoding.shape[0]\n",
    "index_array=np.full((num_rows,1),2)\n",
    "index_array\n",
    "array_with_index = np.hstack((index_array, encoding))\n",
    "len(array_with_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=face_recognition.compare_faces(encoding,encoding[1],tolerance=0.4)\n",
    "# print(a)\n",
    "# np.sum(a) > len(a) / 2\n",
    "len(np.mean(encoding,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in grouped_img['cluster_4']:\n",
    "        i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the faces in the image using the default HOG-based model.\n",
    "# This method is fairly accurate, but not as accurate as the CNN model and not GPU accelerated.\n",
    "# See also: find_faces_in_picture_cnn.py\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    \n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "faces_encodings = face_recognition.face_encodings(image, known_face_locations=face_locations)\n",
    "temp=faces_encodings\n",
    "faces_encodings.append(temp[:])\n",
    "len(faces_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Loop through each person in the training set\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each training image for the current person\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # If there are no people (or too many people) in a training image, skip the image.\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                # Add face encoding for current image to the training set\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    # Determine how many neighbors to use for weighting in the KNN classifier\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    # Create and train the KNN classifier\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    # Save the trained KNN classifier\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_landmarks_list)))\n",
    "\n",
    "# Create a PIL imagedraw object so we can draw on the picture\n",
    "pil_image = Image.fromarray(image)\n",
    "d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "\n",
    "    # Print the location of each facial feature in this image\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        print(\"The {} in this face has the following points: {}\".format(facial_feature, face_landmarks[facial_feature]))\n",
    "\n",
    "    # Let's trace out each facial feature in the image with a line!\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        d.line(face_landmarks[facial_feature], width=5)\n",
    "\n",
    "# Show the picture\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
