{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "login(\"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\")\n",
    "\n",
    "# loader = PyPDFLoader(\"../segregationforce.pdf\")\n",
    "pdf_reader = PdfReader(\"../segregationforce.pdf\")\n",
    "# Text variable will store the pdf text\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "        \n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018;F r y et al. 2018; Saitoh & Tighe 2019; Duan et al. 2020 ; Jing et al. 2020 ). This\\nstabilizing force reduces the granular temperature in the streamwise direction but does not\\naffect the rheological behaviour (Jing et al. 2020 ) or segregation (Jing et al. 2021), and the\\nconstant shear rate eliminates forces associated with shear gradients (Fan & Hill 2011a,b;\\nGuillard et al. 2016; Jing et al. 2021). An overburden pressure P0equal to the pressure at\\nad e p t ho f Hw=20dl(i.e.P0=ρφgHwwhere the bulk solid fraction φvaries from 0.56\\nto 0.59 depending on ﬂow conditions) is applied using a massive ﬂat frictional top wall\\nthat is free to move vertically (ﬂuctuates by ±2 % or less after an initial rapid dilata tion\\nof the particles at ﬂow onset) and moves horizontally at a velocity determined by the\\nconstant-shear -rate velocity proﬁle. The inertial number, I=˙γ¯d√ρ/P, varies between\\n0.06 to 0.26 depending on the ﬂow conditions, indicating a dense granular ﬂow.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_text(text):\n",
    "    # Split the text into chunks using Langchain's CharacterTextSplitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    #\n",
    "    model_name = 'maidalun1020/bce-embedding-base_v1'\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'batch_size': 64, 'normalize_embeddings': True, 'show_progress_bar': False}\n",
    "    embed_model = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    # Convert the chunks of text into embeddings to form a knowledge base\n",
    "    knowledgeBase = FAISS.from_texts(chunks, embed_model)\n",
    "    \n",
    "    return knowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeBase = process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='GOLICK , L.A. & D ANIELS , K.E. 2009 Mixing and segregation rates in sheared granular materials. Phys.\\nRev.E80, 042301.\\n935R1-12\\nhttps://doi.org/10.1017/jfm.2022.12\\n Published online by Cambridge University PressClosing the gap between single intruders and mixtures\\nGRAY, J.M.N.T. 2018 Particle segregation in dense granular ﬂows. Annu. Rev. Fluid Mech. 50, 407–433.\\nGRAY, J.M.N.T. & T HORNTON , A.R. 2005 A theory for particle size segregation in shallow granular\\nfree-surface ﬂows. Proc. R. Soc. Lond. A461(2057), 1447–1473.\\nGUILLARD ,F . ,F ORTERRE ,Y .&P OULIQUEN , O. 2016 Scaling laws for segregation forces in dense sheared\\ngranular ﬂows. J. Fluid Mech. 807,R 1 .\\nHE,D .&E KERE , N.N. 2004 Effect of particle size ratio on the conducting percolation threshold of granular\\nconductive–insulating composites. J. Phys. D: Appl. Phys. 37(13), 1848–1852.\\nISNER , A.B., U MBANHOWAR , P.B., O TTINO ,J . M .&L UEPTOW , R.M. 2020 Axisymmetric granular ﬂow')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = knowledgeBase.similarity_search(\"diffusion\",k=2)\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I like apples'),\n",
       " Document(page_content='Apples and oranges are fruits')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'apples'\n",
    "passages = [\n",
    "        'I like apples', \n",
    "        'I like oranges', \n",
    "        'Apples and oranges are fruits'\n",
    "    ]\n",
    "  \n",
    "# init embedding model\n",
    "model_name = 'maidalun1020/bce-embedding-base_v1'\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'batch_size': 64, 'normalize_embeddings': True, 'show_progress_bar': False}\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    "  )\n",
    "\n",
    "# example #2. langchain retriever example\n",
    "faiss_vectorstore = FAISS.from_texts(passages, embed_model, distance_strategy=DistanceStrategy.MAX_INNER_PRODUCT)\n",
    "\n",
    "retriever = faiss_vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"score_threshold\": 0.5, \"k\": 3})\n",
    "\n",
    "related_passages = retriever.get_relevant_documents(query)\n",
    "related_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "# from htmlTemplates import css, bot_template, user_template\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    model_name = 'maidalun1020/bce-embedding-base_v1'\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'batch_size': 64, 'normalize_embeddings': True, 'show_progress_bar': False}\n",
    "    embed_model = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    # embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embed_model)\n",
    "    return vectorstore\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    # llm = ChatOpenAI()\n",
    "    llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain\n",
    "\n",
    "# pdf_reader = PdfReader(\"../segregationforce.pdf\")\n",
    "raw_text = get_pdf_text([\"../segregationforce.pdf\"])\n",
    "text_chunks = get_text_chunks(raw_text)\n",
    "vectorstore = get_vectorstore(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
