{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beijing\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import find_dotenv,load_dotenv\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "llm=GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3,google_api_key=GOOGLE_API_KEY)\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-base\",model_kwargs={\"temperature\":0.3,\"max_length\":64})\n",
    "\n",
    "output=llm.invoke(\"Where is the capital of China\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shanghai'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "user_template=\"where is the captial of {nation}\"\n",
    "prompt=PromptTemplate(template=user_template,input_variables=['nation'])\n",
    "chain = LLMChain(llm=llm_huggingface, prompt=prompt)\n",
    "chain.run(nation=\"china\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qingdao'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain1=LLMChain(llm=llm_huggingface,prompt=PromptTemplate(template=\"where is the capital of {nation}\",input_variables=['nation']))\n",
    "chain2=LLMChain(llm=llm_huggingface,prompt=PromptTemplate(template=\"suggest me some places to visit in {capital}\",input_variables=['capital']))\n",
    "chain=SimpleSequentialChain(chains=[chain1,chain2])\n",
    "chain.run('china')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. Why did the AI cross the road? To get to the other algorithm.\\n\\n2. What do you call an AI that's always telling jokes? A pun-isher.\\n\\n3. Why did the AI get a degree in computer science? To become a byte-lingual.\\n\\n4. What's the difference between an AI and a human? An AI doesn't need a coffee break to process information.\\n\\n5. Why did the AI get a job as a programmer? Because it was tired of being a know-it-all.\\n\\n6. What do you call an AI that's always making mistakes? A bug-droid.\\n\\n7. Why did the AI get a job as a therapist? To help people with their algorithm-related problems.\\n\\n8. What's the difference between an AI and a politician? An AI doesn't make promises it can't keep.\\n\\n9. Why did the AI get a job as a teacher? To help students learn about the future.\\n\\n10. What do you call an AI that's always getting into trouble? A byte-mare.\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chatllm = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.3,google_api_key=GOOGLE_API_KEY,convert_system_message_to_human=True)\n",
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' sharp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")\n",
    "    \n",
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "])\n",
    "\n",
    "chain=chatprompt|chatllm|Commaseperatedoutput()\n",
    "chain.invoke({\"text\":\"intelligent\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
